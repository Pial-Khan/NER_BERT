{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_BERT.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOiIyhZPJ+XOybvg4rmmDON",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pial-Khan/NER_BERT/blob/main/NER_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPpMPKGsIzS-"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "#import os\n",
        "#print(os.listdir(\"../input\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output.\n",
        "from tqdm import tqdm, trange"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nKa-JP8I2C9"
      },
      "source": [
        "input_data = pd.read_csv(\"clean_ner_all_campaign_data.csv\", encoding=\"UTF-8\")\n",
        "#input_data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_jxyiNsI2BC",
        "outputId": "1f338192-80b2-4c52-ca1d-edca90cf0a8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "input_data = input_data.fillna(method=\"ffill\")\n",
        "input_data.tail(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_no</th>\n",
              "      <th>data</th>\n",
              "      <th>Word</th>\n",
              "      <th>position</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>165704</th>\n",
              "      <td>14716</td>\n",
              "      <td>এ ঘটনায় হামলাকারীদের দৃষ্টান্তমূলক শাস্তির দাব...</td>\n",
              "      <td>দৃষ্টান্তমূলক</td>\n",
              "      <td>4</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165705</th>\n",
              "      <td>14716</td>\n",
              "      <td>এ ঘটনায় হামলাকারীদের দৃষ্টান্তমূলক শাস্তির দাব...</td>\n",
              "      <td>শাস্তির</td>\n",
              "      <td>5</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165706</th>\n",
              "      <td>14716</td>\n",
              "      <td>এ ঘটনায় হামলাকারীদের দৃষ্টান্তমূলক শাস্তির দাব...</td>\n",
              "      <td>দাবিতে</td>\n",
              "      <td>6</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165707</th>\n",
              "      <td>14716</td>\n",
              "      <td>এ ঘটনায় হামলাকারীদের দৃষ্টান্তমূলক শাস্তির দাব...</td>\n",
              "      <td>শিক্ষকদের</td>\n",
              "      <td>7</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165708</th>\n",
              "      <td>14716</td>\n",
              "      <td>এ ঘটনায় হামলাকারীদের দৃষ্টান্তমূলক শাস্তির দাব...</td>\n",
              "      <td>কর্মবিরতির</td>\n",
              "      <td>8</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165709</th>\n",
              "      <td>14716</td>\n",
              "      <td>এ ঘটনায় হামলাকারীদের দৃষ্টান্তমূলক শাস্তির দাব...</td>\n",
              "      <td>ঘোষণা</td>\n",
              "      <td>9</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165710</th>\n",
              "      <td>14716</td>\n",
              "      <td>এ ঘটনায় হামলাকারীদের দৃষ্টান্তমূলক শাস্তির দাব...</td>\n",
              "      <td>দিয়েছে</td>\n",
              "      <td>10</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165711</th>\n",
              "      <td>14716</td>\n",
              "      <td>এ ঘটনায় হামলাকারীদের দৃষ্টান্তমূলক শাস্তির দাব...</td>\n",
              "      <td>বিশ্ববিদ্যালয়</td>\n",
              "      <td>11</td>\n",
              "      <td>B-ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165712</th>\n",
              "      <td>14716</td>\n",
              "      <td>এ ঘটনায় হামলাকারীদের দৃষ্টান্তমূলক শাস্তির দাব...</td>\n",
              "      <td>শিক্ষক</td>\n",
              "      <td>12</td>\n",
              "      <td>I-ORG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165713</th>\n",
              "      <td>14716</td>\n",
              "      <td>এ ঘটনায় হামলাকারীদের দৃষ্টান্তমূলক শাস্তির দাব...</td>\n",
              "      <td>সমিতি</td>\n",
              "      <td>13</td>\n",
              "      <td>I-ORG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        sentence_no  ...    Tag\n",
              "165704        14716  ...      O\n",
              "165705        14716  ...      O\n",
              "165706        14716  ...      O\n",
              "165707        14716  ...      O\n",
              "165708        14716  ...      O\n",
              "165709        14716  ...      O\n",
              "165710        14716  ...      O\n",
              "165711        14716  ...  B-ORG\n",
              "165712        14716  ...  I-ORG\n",
              "165713        14716  ...  I-ORG\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fTX8AH7I18J",
        "outputId": "93703b08-561a-4c86-b5c5-2ffb0cb2538d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "words_list = list(set(input_data[\"Word\"].values))\n",
        "words_list[:10]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['নারী',\n",
              " 'সপ্তপর্ণা',\n",
              " 'পড়ান',\n",
              " 'প্রভাবশালীদের',\n",
              " 'প্রবল',\n",
              " 'বাঁচাব',\n",
              " 'কোম্পানিজ',\n",
              " 'বাণিজ্যমন্ত্রী',\n",
              " 'বিব্রতকর',\n",
              " 'মহাসড়কগুলো']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wZogExFI13G",
        "outputId": "199643d5-5d2b-4800-ef82-7d3f76f2423e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "number_words = len(words_list); number_words # number of unique words in the corpus"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20793"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Fh9EmYuI1y_"
      },
      "source": [
        "class RetrieveSentance(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "        function = lambda s: [(w, t) for w, t in zip(s[\"Word\"].values.tolist(),\n",
        "                                                           s[\"Tag\"].values.tolist())]\n",
        "        self.grouped = self.data.groupby(\"sentence_no\").apply(function)\n",
        "        self.sentences = [s for s in self.grouped]\n",
        "    \n",
        "    def retrieve(self):\n",
        "        try:\n",
        "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s\n",
        "        except:\n",
        "            return None"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQc1rYpmI1vp",
        "outputId": "ee0f5b1a-8bd4-486a-fa36-34d54e49d966",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Sentences = RetrieveSentance(input_data)\n",
        "Sentences"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.RetrieveSentance at 0x7fb20e15f908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYs-2W9lI1nU",
        "outputId": "db5d48d4-e3c0-4d47-f535-790df1767c74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Sentences_list = [\" \".join([s[0] for s in sent]) for sent in Sentences.sentences]\n",
        "Sentences_list[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'এরশাদকে নিয়ে গণতন্ত্র হত্যা করেছে শেখ হাসিনা - মির্জা ফখরুল'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9D_I8irI1lv",
        "outputId": "e757fe3a-f021-4793-c2f5-a9f5698bc8e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(Sentences_list) #number of sentences "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11979"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezgp3iwFI1kG",
        "outputId": "c0946214-ff88-4f8f-e0f6-456c22487b74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "labels = [[s[1] for s in sent] for sent in Sentences.sentences]\n",
        "print(labels[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['B-PER', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'B-PER', 'I-PER']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWcCVLPiI1fQ",
        "outputId": "873c2601-24c1-45ea-816c-e5289cd8d891",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "labels [0] # list of lists of dimension (sentences,labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['B-PER', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'B-PER', 'I-PER']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ch8s8SsI1ds"
      },
      "source": [
        "tags2vals = list(set(input_data[\"Tag\"].values))\n",
        "tag2idx = {t: i for i, t in enumerate(tags2vals)}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xM9cAa3I1ZT",
        "outputId": "4b3ca9e7-5b17-4152-ec15-c7b5d0aa04e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tags2vals # 11 kinds of tags "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I-ORG',\n",
              " 'I-EVE',\n",
              " 'B-Date',\n",
              " 'I-LOC',\n",
              " 'I-Date',\n",
              " 'B-LOC',\n",
              " 'B-PER',\n",
              " 'B-ORG',\n",
              " 'B-EVE',\n",
              " 'O',\n",
              " 'I-PER']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7jOo4MJI1V6",
        "outputId": "013f3e4b-8e28-4d55-fc41-084371fd45c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tag2idx # indexing the tag "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-Date': 2,\n",
              " 'B-EVE': 8,\n",
              " 'B-LOC': 5,\n",
              " 'B-ORG': 7,\n",
              " 'B-PER': 6,\n",
              " 'I-Date': 4,\n",
              " 'I-EVE': 1,\n",
              " 'I-LOC': 3,\n",
              " 'I-ORG': 0,\n",
              " 'I-PER': 10,\n",
              " 'O': 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71m53LWORCVM",
        "outputId": "42e5a125-a34c-4aeb-c3cc-4ea443f41ec1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install bert-tensorflow\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/16/0f9376af49c6adcfbaf2470a8f500105a74dd803aa54ac0110af445837b5/bert_tensorflow-1.0.4-py2.py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 27.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 12.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 51kB 11.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 61kB 10.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.15.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNJ-fgmPRcta",
        "outputId": "70e0f637-3694-45a9-d562-162e85634eba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install pytorch_pretrained_bert"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 23.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 10.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 8.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 8.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.6.0+cu101)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/b5/78c837d962dd2b629ac551647c61537c56fe8f669d9e9efbed1abd798e65/boto3-1.16.10.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Collecting botocore<1.20.0,>=1.19.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/11/765dce0f69eb6f6db6a189e1848f553575a0189b24bd059eaa24fd9e003d/botocore-1.19.10-py2.py3-none-any.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 21.4MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.10->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.10->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Building wheels for collected packages: boto3\n",
            "  Building wheel for boto3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for boto3: filename=boto3-1.16.10-py2.py3-none-any.whl size=128451 sha256=22480d4571dd4afe270befe02b2e003e7c0ecc1a26dd06734e62e487d0917c50\n",
            "  Stored in directory: /root/.cache/pip/wheels/36/dd/27/cf4486e326eeb099cbe273be73945d394f66914c0f14ac3b09\n",
            "Successfully built boto3\n",
            "\u001b[31mERROR: botocore 1.19.10 has requirement urllib3<1.26,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "Successfully installed boto3-1.16.10 botocore-1.19.10 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRoGRljWI1Qf"
      },
      "source": [
        "import torch\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgE_aqZWI1II"
      },
      "source": [
        "max_seq_len = 75 # tokens\n",
        "batch_s = 32 # batch size"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiCDX2y0I06d"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJFDomFkJg_i",
        "outputId": "6dc71264-1295-4a1f-9147-6efe7cc33161",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "torch.cuda.get_device_name(0) "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla T4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmvgaM4TJg1K",
        "outputId": "ebc76c54-9e4b-46a0-c412-43e67e7d08f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The pre-trained model you are loading is a cased model but you have not set `do_lower_case` to False. We are setting `do_lower_case=False` for you but you may want to check this behavior.\n",
            "100%|██████████| 213450/213450 [00:00<00:00, 19285973.78B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mNOD2XkJo9g",
        "outputId": "1f1f2d76-f0c6-40b5-e68f-eb4fc19ba14b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in Sentences_list]\n",
        "print(tokenized_texts[0])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['এ', '##র', '##শ', '##া', '##দ', '##ক', '##ে', 'ন', '##ি', '##য়', '##ে', '[UNK]', 'হ', '##ত', '##্', '##য', '##া', 'ক', '##র', '##ে', '##ছ', '##ে', 'শ', '##ে', '##খ', 'হ', '##া', '##স', '##ি', '##ন', '##া', '-', 'ম', '##ি', '##র', '##্', '##জ', '##া', '[UNK]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xgh42FVJpR5",
        "outputId": "b4b3da97-1f89-4e36-cfca-e0600757fd73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(tokenized_texts)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11979"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0Bg4RIEJp4g",
        "outputId": "82e96f98-c25a-47d4-dcd1-6aceee8a2993",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(tokenized_texts[1])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['হ', '##ু', '##স', '##ে', '##ই', '##ন', 'ম', '##ু', '##হ', '##ম', '##্', '##ম', '##দ', 'এ', '##র', '##শ', '##া', '##দ', '##ক', '##ে', 'ন', '##ি', '##য়', '##ে', 'প', '##্', '##র', '##ধ', '##া', '##ন', '##ম', '##ন', '##্', '##ত', '##্', '##র', '##ী', 'শ', '##ে', '##খ', 'হ', '##া', '##স', '##ি', '##ন', '##া', 'দ', '##ে', '##শ', '##ে', '##র', '[UNK]', 'হ', '##ত', '##্', '##য', '##া', 'ক', '##র', '##ে', '##ছ', '##ে', 'ব', '##ল', '##ে', '[UNK]', 'ক', '##র', '##ে', '##ছ', '##ে', '##ন', 'ব', '##ি', '##এ', '##ন', '##প', '##ি', 'ম', '##হ', '##া', '##স', '##চ', '##ি', '##ব', 'ম', '##ি', '##র', '##্', '##জ', '##া', '[UNK]', 'ই', '##স', '##ল', '##া', '##ম', 'আ', '##ল', '##ম', '##গ', '##ী', '##র']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLZ6NnQ2Jpv4",
        "outputId": "39fec759-a897-422b-d3f6-06897f5de955",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n",
        "                          maxlen=max_seq_len, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (605 > 512). Running this sequence through BERT will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (713 > 512). Running this sequence through BERT will result in indexing errors\n",
            "Token indices sequence length is longer than the specified maximum  sequence length for this BERT model (517 > 512). Running this sequence through BERT will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Unt66RCJpEL"
      },
      "source": [
        "Y = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n",
        "                     maxlen=max_seq_len, value=tag2idx[\"O\"], padding=\"post\",\n",
        "                     dtype=\"long\", truncating=\"post\")"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apFIO4kGJo0A",
        "outputId": "69c2c34e-7060-4424-ad99-6a01169d2908",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X.shape # (sentences, maximum sequence length)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11979, 75)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8nbD0V4J3h6",
        "outputId": "b1d2b617-6437-45ce-8419-d7ed7d4002ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Y.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11979, 75)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c5K0pJtJ4CX",
        "outputId": "c2d17bae-7c1c-4e19-cfa3-be4929ba844c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  639, 28560, 28562, ...,     0,     0,     0],\n",
              "       [  661, 28569, 28563, ...,   654, 28567, 28542],\n",
              "       [  648, 28567, 28555, ..., 28548, 28567, 28561],\n",
              "       ...,\n",
              "       [  648, 28557, 28570, ...,     0,     0,     0],\n",
              "       [  648, 28566, 28544, ...,     0,     0,     0],\n",
              "       [  639,   100,   661, ...,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2G8oRRUJ4mo",
        "outputId": "9252ec66-5648-466e-8536-c1aaf6c721cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Y"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6,  9,  9, ...,  9,  9,  9],\n",
              "       [ 6, 10, 10, ...,  9,  9,  9],\n",
              "       [ 9,  9,  9, ...,  9,  9,  9],\n",
              "       ...,\n",
              "       [ 9,  9,  9, ...,  9,  9,  9],\n",
              "       [ 9,  9,  9, ...,  9,  9,  9],\n",
              "       [ 9,  9,  9, ...,  9,  9,  9]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES_kTt6WJ43X"
      },
      "source": [
        "attention_masks = [[float(i>0) for i in ii] for ii in X]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj4p_EpxJ4bP",
        "outputId": "be0acecd-bb11-495b-d20e-fd8a4e6dbcaa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(attention_masks) # list of lists of shape (sentences, labels )"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11979"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SQ-1ON8J33w",
        "outputId": "52deec29-6010-42fc-a68b-b4f5ebe95bf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "attention_masks[0]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gig2U1iJ3X_"
      },
      "source": [
        "X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, \n",
        "                                                            random_state=20, test_size=0.1)\n",
        "Mask_train, Mask_valid, _, _ = train_test_split(attention_masks, X,\n",
        "                                             random_state=20, test_size=0.1)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHr6kb5TKJCr"
      },
      "source": [
        "X_train = torch.tensor(X_train)\n",
        "X_valid = torch.tensor(X_valid)\n",
        "Y_train = torch.tensor(Y_train)\n",
        "Y_valid = torch.tensor(Y_valid)\n",
        "Mask_train = torch.tensor(Mask_train)\n",
        "Mask_valid = torch.tensor(Mask_valid)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKgsOccWKJe0"
      },
      "source": [
        "data_train = TensorDataset(X_train, Mask_train, Y_train)\n",
        "data_train_sampler = RandomSampler(data_train)\n",
        "DL_train = DataLoader(data_train, sampler=data_train_sampler, batch_size=batch_s)\n",
        "\n",
        "data_valid = TensorDataset(X_valid, Mask_valid, Y_valid)\n",
        "data_valid_sampler = SequentialSampler(data_valid)\n",
        "DL_valid = DataLoader(data_valid, sampler=data_valid_sampler, batch_size=batch_s)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7-IRsKSKJx4",
        "outputId": "f8f79b99-864a-4d79-902e-cf2b0ca4a174",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = BertForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=len(tag2idx))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 404400730/404400730 [00:09<00:00, 41776328.58B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTUwXuBlKJVa"
      },
      "source": [
        "model.cuda();"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKCjw_-bKI3a"
      },
      "source": [
        "FULL_FINETUNING = True\n",
        "if FULL_FINETUNING:\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    param_optimizer = list(model.classifier.named_parameters()) \n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31NAhkWcWBbq",
        "outputId": "80f48c2c-5d34-42f4-99a4-faf8393653b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install seqeval"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\r\u001b[K     |███████▌                        | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20kB 25.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30kB 21.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40kB 17.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (0.17.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=dd1a9d2497bb52e388cd6f7aabb1e5a964ee0fbb65c6b4f2a341f80e077b9247\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tFx3trYKXBB"
      },
      "source": [
        "from seqeval.metrics import f1_score\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOZTyEXYKXhZ",
        "outputId": "67d24cd4-28ae-40cd-a8c6-26d6b6887834",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epochs = 5\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "    # TRAIN loop\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(DL_train):\n",
        "        # add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        # forward pass\n",
        "        loss = model(b_input_ids, token_type_ids=None,\n",
        "                     attention_mask=b_input_mask, labels=b_labels)\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        # track train loss\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        model.zero_grad()\n",
        "    # print train loss per epoch\n",
        "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "    # VALIDATION on validation set\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    predictions , true_labels = [], []\n",
        "    for batch in DL_valid:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
        "                                  attention_mask=b_input_mask, labels=b_labels)\n",
        "            logits = model(b_input_ids, token_type_ids=None,\n",
        "                           attention_mask=b_input_mask)\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "        true_labels.append(label_ids)\n",
        "        \n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        eval_loss += tmp_eval_loss.mean().item()\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        \n",
        "        nb_eval_examples += b_input_ids.size(0)\n",
        "        nb_eval_steps += 1\n",
        "    eval_loss = eval_loss/nb_eval_steps\n",
        "    print(\"Validation loss: {}\".format(eval_loss))\n",
        "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "    pred_tags = [tags2vals[p_i] for p in predictions for p_i in p]\n",
        "    valid_tags = [tags2vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
        "    #print(\"F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))\n",
        "    "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.1143455079892092\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Epoch:  20%|██        | 1/5 [03:05<12:21, 185.37s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.1657932863423699\n",
            "Validation Accuracy: 0.9670692355889725\n",
            "Train loss: 0.10598194761649438\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Epoch:  40%|████      | 2/5 [06:10<09:16, 185.40s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.16548379294966398\n",
            "Validation Accuracy: 0.969779135338346\n",
            "Train loss: 0.09901054561668758\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Epoch:  60%|██████    | 3/5 [09:16<06:10, 185.39s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.17341127932855957\n",
            "Validation Accuracy: 0.968660714285714\n",
            "Train loss: 0.09281937156745872\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Epoch:  80%|████████  | 4/5 [12:21<03:05, 185.37s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.16951388512787066\n",
            "Validation Accuracy: 0.96859335839599\n",
            "Train loss: 0.08713609312912476\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "Epoch: 100%|██████████| 5/5 [15:27<00:00, 185.41s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.17496033542250333\n",
            "Validation Accuracy: 0.9697916666666666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Issje7yrKYG5",
        "outputId": "8498da00-963c-4004-e1f5-afcd22324d1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "for batch in DL_valid:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
        "                              attention_mask=b_input_mask, labels=b_labels)\n",
        "        logits = model(b_input_ids, token_type_ids=None,\n",
        "                       attention_mask=b_input_mask)\n",
        "        \n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    true_labels.append(label_ids)\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "    eval_loss += tmp_eval_loss.mean().item()\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    nb_eval_examples += b_input_ids.size(0)\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "pred_tags = [[tags2vals[p_i] for p_i in p] for p in predictions]\n",
        "valid_tags = [[tags2vals[l_ii] for l_ii in l_i] for l in true_labels for l_i in l ]\n",
        "print(\"Validation loss: {}\".format(eval_loss/nb_eval_steps))\n",
        "print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"Validation F1-Score: {}\".format(f1_score(pred_tags, valid_tags)))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.17496033542250333\n",
            "Validation Accuracy: 0.9697916666666666\n",
            "Validation F1-Score: 0.24284666177549522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yxvgpb-dKW1h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}